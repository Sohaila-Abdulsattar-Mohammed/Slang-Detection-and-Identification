{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Slang Identification"
      ],
      "metadata": {
        "id": "CzstB-Ojcytl"
      },
      "id": "CzstB-Ojcytl"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "pIND3VaIlOgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "221c75a9-fefc-4d43-ca8a-00c6a523e557"
      },
      "id": "pIND3VaIlOgz",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.17.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80e7473f-9077-45fa-9bc7-7df1ac01258c",
      "metadata": {
        "id": "80e7473f-9077-45fa-9bc7-7df1ac01258c"
      },
      "source": [
        "### imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a32b5c69-b8b2-4807-b6c5-d5ed3d237b7e",
      "metadata": {
        "id": "a32b5c69-b8b2-4807-b6c5-d5ed3d237b7e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import DatasetDict, Dataset, load_dataset\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from transformers import DataCollatorWithPadding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c799a68-36aa-4ecc-8c57-2becf92b38e2",
      "metadata": {
        "id": "2c799a68-36aa-4ecc-8c57-2becf92b38e2"
      },
      "source": [
        "### load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "f4fbd278-3ace-49cb-9765-5dbed896d5ae",
      "metadata": {
        "id": "f4fbd278-3ace-49cb-9765-5dbed896d5ae"
      },
      "outputs": [],
      "source": [
        "dataset_dict = load_dataset(\"SohailaMohammed/BERTSlangDetectionInitial\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "edb6b85e-9b43-44cc-a335-e415635d7c31",
      "metadata": {
        "id": "edb6b85e-9b43-44cc-a335-e415635d7c31",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6bcf1a6a-5979-4b36-f1fd-e133464ffcdf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 2490\n",
              "    })\n",
              "    dev: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 534\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'labels'],\n",
              "        num_rows: 534\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "dataset_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf82a01",
      "metadata": {
        "id": "2bf82a01"
      },
      "source": [
        "### Train Teacher Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "ec0311bd",
      "metadata": {
        "id": "ec0311bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b74adf3c-1d43-4bbd-9903-5c619f39db9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load model directly\n",
        "model_path = \"google-bert/bert-large-uncased\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "id2label = {0: \"Not Slang\", 1: \"Slang\"}\n",
        "label2id = {\"Not Slang\": 0, \"Slang\": 1}\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path,\n",
        "                                                           num_labels=2,\n",
        "                                                           id2label=id2label,\n",
        "                                                           label2id=label2id,)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826084b6",
      "metadata": {
        "id": "826084b6"
      },
      "source": [
        "#### Freeze base model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "03aa44f2",
      "metadata": {
        "id": "03aa44f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c64febe-96b2-4477-d024-4dcea62bb6d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight True\n",
            "bert.embeddings.position_embeddings.weight True\n",
            "bert.embeddings.token_type_embeddings.weight True\n",
            "bert.embeddings.LayerNorm.weight True\n",
            "bert.embeddings.LayerNorm.bias True\n",
            "bert.encoder.layer.0.attention.self.query.weight True\n",
            "bert.encoder.layer.0.attention.self.query.bias True\n",
            "bert.encoder.layer.0.attention.self.key.weight True\n",
            "bert.encoder.layer.0.attention.self.key.bias True\n",
            "bert.encoder.layer.0.attention.self.value.weight True\n",
            "bert.encoder.layer.0.attention.self.value.bias True\n",
            "bert.encoder.layer.0.attention.output.dense.weight True\n",
            "bert.encoder.layer.0.attention.output.dense.bias True\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.0.intermediate.dense.weight True\n",
            "bert.encoder.layer.0.intermediate.dense.bias True\n",
            "bert.encoder.layer.0.output.dense.weight True\n",
            "bert.encoder.layer.0.output.dense.bias True\n",
            "bert.encoder.layer.0.output.LayerNorm.weight True\n",
            "bert.encoder.layer.0.output.LayerNorm.bias True\n",
            "bert.encoder.layer.1.attention.self.query.weight True\n",
            "bert.encoder.layer.1.attention.self.query.bias True\n",
            "bert.encoder.layer.1.attention.self.key.weight True\n",
            "bert.encoder.layer.1.attention.self.key.bias True\n",
            "bert.encoder.layer.1.attention.self.value.weight True\n",
            "bert.encoder.layer.1.attention.self.value.bias True\n",
            "bert.encoder.layer.1.attention.output.dense.weight True\n",
            "bert.encoder.layer.1.attention.output.dense.bias True\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.1.intermediate.dense.weight True\n",
            "bert.encoder.layer.1.intermediate.dense.bias True\n",
            "bert.encoder.layer.1.output.dense.weight True\n",
            "bert.encoder.layer.1.output.dense.bias True\n",
            "bert.encoder.layer.1.output.LayerNorm.weight True\n",
            "bert.encoder.layer.1.output.LayerNorm.bias True\n",
            "bert.encoder.layer.2.attention.self.query.weight True\n",
            "bert.encoder.layer.2.attention.self.query.bias True\n",
            "bert.encoder.layer.2.attention.self.key.weight True\n",
            "bert.encoder.layer.2.attention.self.key.bias True\n",
            "bert.encoder.layer.2.attention.self.value.weight True\n",
            "bert.encoder.layer.2.attention.self.value.bias True\n",
            "bert.encoder.layer.2.attention.output.dense.weight True\n",
            "bert.encoder.layer.2.attention.output.dense.bias True\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.2.intermediate.dense.weight True\n",
            "bert.encoder.layer.2.intermediate.dense.bias True\n",
            "bert.encoder.layer.2.output.dense.weight True\n",
            "bert.encoder.layer.2.output.dense.bias True\n",
            "bert.encoder.layer.2.output.LayerNorm.weight True\n",
            "bert.encoder.layer.2.output.LayerNorm.bias True\n",
            "bert.encoder.layer.3.attention.self.query.weight True\n",
            "bert.encoder.layer.3.attention.self.query.bias True\n",
            "bert.encoder.layer.3.attention.self.key.weight True\n",
            "bert.encoder.layer.3.attention.self.key.bias True\n",
            "bert.encoder.layer.3.attention.self.value.weight True\n",
            "bert.encoder.layer.3.attention.self.value.bias True\n",
            "bert.encoder.layer.3.attention.output.dense.weight True\n",
            "bert.encoder.layer.3.attention.output.dense.bias True\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.3.intermediate.dense.weight True\n",
            "bert.encoder.layer.3.intermediate.dense.bias True\n",
            "bert.encoder.layer.3.output.dense.weight True\n",
            "bert.encoder.layer.3.output.dense.bias True\n",
            "bert.encoder.layer.3.output.LayerNorm.weight True\n",
            "bert.encoder.layer.3.output.LayerNorm.bias True\n",
            "bert.encoder.layer.4.attention.self.query.weight True\n",
            "bert.encoder.layer.4.attention.self.query.bias True\n",
            "bert.encoder.layer.4.attention.self.key.weight True\n",
            "bert.encoder.layer.4.attention.self.key.bias True\n",
            "bert.encoder.layer.4.attention.self.value.weight True\n",
            "bert.encoder.layer.4.attention.self.value.bias True\n",
            "bert.encoder.layer.4.attention.output.dense.weight True\n",
            "bert.encoder.layer.4.attention.output.dense.bias True\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.4.intermediate.dense.weight True\n",
            "bert.encoder.layer.4.intermediate.dense.bias True\n",
            "bert.encoder.layer.4.output.dense.weight True\n",
            "bert.encoder.layer.4.output.dense.bias True\n",
            "bert.encoder.layer.4.output.LayerNorm.weight True\n",
            "bert.encoder.layer.4.output.LayerNorm.bias True\n",
            "bert.encoder.layer.5.attention.self.query.weight True\n",
            "bert.encoder.layer.5.attention.self.query.bias True\n",
            "bert.encoder.layer.5.attention.self.key.weight True\n",
            "bert.encoder.layer.5.attention.self.key.bias True\n",
            "bert.encoder.layer.5.attention.self.value.weight True\n",
            "bert.encoder.layer.5.attention.self.value.bias True\n",
            "bert.encoder.layer.5.attention.output.dense.weight True\n",
            "bert.encoder.layer.5.attention.output.dense.bias True\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.5.intermediate.dense.weight True\n",
            "bert.encoder.layer.5.intermediate.dense.bias True\n",
            "bert.encoder.layer.5.output.dense.weight True\n",
            "bert.encoder.layer.5.output.dense.bias True\n",
            "bert.encoder.layer.5.output.LayerNorm.weight True\n",
            "bert.encoder.layer.5.output.LayerNorm.bias True\n",
            "bert.encoder.layer.6.attention.self.query.weight True\n",
            "bert.encoder.layer.6.attention.self.query.bias True\n",
            "bert.encoder.layer.6.attention.self.key.weight True\n",
            "bert.encoder.layer.6.attention.self.key.bias True\n",
            "bert.encoder.layer.6.attention.self.value.weight True\n",
            "bert.encoder.layer.6.attention.self.value.bias True\n",
            "bert.encoder.layer.6.attention.output.dense.weight True\n",
            "bert.encoder.layer.6.attention.output.dense.bias True\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.6.intermediate.dense.weight True\n",
            "bert.encoder.layer.6.intermediate.dense.bias True\n",
            "bert.encoder.layer.6.output.dense.weight True\n",
            "bert.encoder.layer.6.output.dense.bias True\n",
            "bert.encoder.layer.6.output.LayerNorm.weight True\n",
            "bert.encoder.layer.6.output.LayerNorm.bias True\n",
            "bert.encoder.layer.7.attention.self.query.weight True\n",
            "bert.encoder.layer.7.attention.self.query.bias True\n",
            "bert.encoder.layer.7.attention.self.key.weight True\n",
            "bert.encoder.layer.7.attention.self.key.bias True\n",
            "bert.encoder.layer.7.attention.self.value.weight True\n",
            "bert.encoder.layer.7.attention.self.value.bias True\n",
            "bert.encoder.layer.7.attention.output.dense.weight True\n",
            "bert.encoder.layer.7.attention.output.dense.bias True\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.7.intermediate.dense.weight True\n",
            "bert.encoder.layer.7.intermediate.dense.bias True\n",
            "bert.encoder.layer.7.output.dense.weight True\n",
            "bert.encoder.layer.7.output.dense.bias True\n",
            "bert.encoder.layer.7.output.LayerNorm.weight True\n",
            "bert.encoder.layer.7.output.LayerNorm.bias True\n",
            "bert.encoder.layer.8.attention.self.query.weight True\n",
            "bert.encoder.layer.8.attention.self.query.bias True\n",
            "bert.encoder.layer.8.attention.self.key.weight True\n",
            "bert.encoder.layer.8.attention.self.key.bias True\n",
            "bert.encoder.layer.8.attention.self.value.weight True\n",
            "bert.encoder.layer.8.attention.self.value.bias True\n",
            "bert.encoder.layer.8.attention.output.dense.weight True\n",
            "bert.encoder.layer.8.attention.output.dense.bias True\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.8.intermediate.dense.weight True\n",
            "bert.encoder.layer.8.intermediate.dense.bias True\n",
            "bert.encoder.layer.8.output.dense.weight True\n",
            "bert.encoder.layer.8.output.dense.bias True\n",
            "bert.encoder.layer.8.output.LayerNorm.weight True\n",
            "bert.encoder.layer.8.output.LayerNorm.bias True\n",
            "bert.encoder.layer.9.attention.self.query.weight True\n",
            "bert.encoder.layer.9.attention.self.query.bias True\n",
            "bert.encoder.layer.9.attention.self.key.weight True\n",
            "bert.encoder.layer.9.attention.self.key.bias True\n",
            "bert.encoder.layer.9.attention.self.value.weight True\n",
            "bert.encoder.layer.9.attention.self.value.bias True\n",
            "bert.encoder.layer.9.attention.output.dense.weight True\n",
            "bert.encoder.layer.9.attention.output.dense.bias True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.9.intermediate.dense.weight True\n",
            "bert.encoder.layer.9.intermediate.dense.bias True\n",
            "bert.encoder.layer.9.output.dense.weight True\n",
            "bert.encoder.layer.9.output.dense.bias True\n",
            "bert.encoder.layer.9.output.LayerNorm.weight True\n",
            "bert.encoder.layer.9.output.LayerNorm.bias True\n",
            "bert.encoder.layer.10.attention.self.query.weight True\n",
            "bert.encoder.layer.10.attention.self.query.bias True\n",
            "bert.encoder.layer.10.attention.self.key.weight True\n",
            "bert.encoder.layer.10.attention.self.key.bias True\n",
            "bert.encoder.layer.10.attention.self.value.weight True\n",
            "bert.encoder.layer.10.attention.self.value.bias True\n",
            "bert.encoder.layer.10.attention.output.dense.weight True\n",
            "bert.encoder.layer.10.attention.output.dense.bias True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.10.intermediate.dense.weight True\n",
            "bert.encoder.layer.10.intermediate.dense.bias True\n",
            "bert.encoder.layer.10.output.dense.weight True\n",
            "bert.encoder.layer.10.output.dense.bias True\n",
            "bert.encoder.layer.10.output.LayerNorm.weight True\n",
            "bert.encoder.layer.10.output.LayerNorm.bias True\n",
            "bert.encoder.layer.11.attention.self.query.weight True\n",
            "bert.encoder.layer.11.attention.self.query.bias True\n",
            "bert.encoder.layer.11.attention.self.key.weight True\n",
            "bert.encoder.layer.11.attention.self.key.bias True\n",
            "bert.encoder.layer.11.attention.self.value.weight True\n",
            "bert.encoder.layer.11.attention.self.value.bias True\n",
            "bert.encoder.layer.11.attention.output.dense.weight True\n",
            "bert.encoder.layer.11.attention.output.dense.bias True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.11.intermediate.dense.weight True\n",
            "bert.encoder.layer.11.intermediate.dense.bias True\n",
            "bert.encoder.layer.11.output.dense.weight True\n",
            "bert.encoder.layer.11.output.dense.bias True\n",
            "bert.encoder.layer.11.output.LayerNorm.weight True\n",
            "bert.encoder.layer.11.output.LayerNorm.bias True\n",
            "bert.encoder.layer.12.attention.self.query.weight True\n",
            "bert.encoder.layer.12.attention.self.query.bias True\n",
            "bert.encoder.layer.12.attention.self.key.weight True\n",
            "bert.encoder.layer.12.attention.self.key.bias True\n",
            "bert.encoder.layer.12.attention.self.value.weight True\n",
            "bert.encoder.layer.12.attention.self.value.bias True\n",
            "bert.encoder.layer.12.attention.output.dense.weight True\n",
            "bert.encoder.layer.12.attention.output.dense.bias True\n",
            "bert.encoder.layer.12.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.12.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.12.intermediate.dense.weight True\n",
            "bert.encoder.layer.12.intermediate.dense.bias True\n",
            "bert.encoder.layer.12.output.dense.weight True\n",
            "bert.encoder.layer.12.output.dense.bias True\n",
            "bert.encoder.layer.12.output.LayerNorm.weight True\n",
            "bert.encoder.layer.12.output.LayerNorm.bias True\n",
            "bert.encoder.layer.13.attention.self.query.weight True\n",
            "bert.encoder.layer.13.attention.self.query.bias True\n",
            "bert.encoder.layer.13.attention.self.key.weight True\n",
            "bert.encoder.layer.13.attention.self.key.bias True\n",
            "bert.encoder.layer.13.attention.self.value.weight True\n",
            "bert.encoder.layer.13.attention.self.value.bias True\n",
            "bert.encoder.layer.13.attention.output.dense.weight True\n",
            "bert.encoder.layer.13.attention.output.dense.bias True\n",
            "bert.encoder.layer.13.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.13.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.13.intermediate.dense.weight True\n",
            "bert.encoder.layer.13.intermediate.dense.bias True\n",
            "bert.encoder.layer.13.output.dense.weight True\n",
            "bert.encoder.layer.13.output.dense.bias True\n",
            "bert.encoder.layer.13.output.LayerNorm.weight True\n",
            "bert.encoder.layer.13.output.LayerNorm.bias True\n",
            "bert.encoder.layer.14.attention.self.query.weight True\n",
            "bert.encoder.layer.14.attention.self.query.bias True\n",
            "bert.encoder.layer.14.attention.self.key.weight True\n",
            "bert.encoder.layer.14.attention.self.key.bias True\n",
            "bert.encoder.layer.14.attention.self.value.weight True\n",
            "bert.encoder.layer.14.attention.self.value.bias True\n",
            "bert.encoder.layer.14.attention.output.dense.weight True\n",
            "bert.encoder.layer.14.attention.output.dense.bias True\n",
            "bert.encoder.layer.14.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.14.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.14.intermediate.dense.weight True\n",
            "bert.encoder.layer.14.intermediate.dense.bias True\n",
            "bert.encoder.layer.14.output.dense.weight True\n",
            "bert.encoder.layer.14.output.dense.bias True\n",
            "bert.encoder.layer.14.output.LayerNorm.weight True\n",
            "bert.encoder.layer.14.output.LayerNorm.bias True\n",
            "bert.encoder.layer.15.attention.self.query.weight True\n",
            "bert.encoder.layer.15.attention.self.query.bias True\n",
            "bert.encoder.layer.15.attention.self.key.weight True\n",
            "bert.encoder.layer.15.attention.self.key.bias True\n",
            "bert.encoder.layer.15.attention.self.value.weight True\n",
            "bert.encoder.layer.15.attention.self.value.bias True\n",
            "bert.encoder.layer.15.attention.output.dense.weight True\n",
            "bert.encoder.layer.15.attention.output.dense.bias True\n",
            "bert.encoder.layer.15.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.15.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.15.intermediate.dense.weight True\n",
            "bert.encoder.layer.15.intermediate.dense.bias True\n",
            "bert.encoder.layer.15.output.dense.weight True\n",
            "bert.encoder.layer.15.output.dense.bias True\n",
            "bert.encoder.layer.15.output.LayerNorm.weight True\n",
            "bert.encoder.layer.15.output.LayerNorm.bias True\n",
            "bert.encoder.layer.16.attention.self.query.weight True\n",
            "bert.encoder.layer.16.attention.self.query.bias True\n",
            "bert.encoder.layer.16.attention.self.key.weight True\n",
            "bert.encoder.layer.16.attention.self.key.bias True\n",
            "bert.encoder.layer.16.attention.self.value.weight True\n",
            "bert.encoder.layer.16.attention.self.value.bias True\n",
            "bert.encoder.layer.16.attention.output.dense.weight True\n",
            "bert.encoder.layer.16.attention.output.dense.bias True\n",
            "bert.encoder.layer.16.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.16.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.16.intermediate.dense.weight True\n",
            "bert.encoder.layer.16.intermediate.dense.bias True\n",
            "bert.encoder.layer.16.output.dense.weight True\n",
            "bert.encoder.layer.16.output.dense.bias True\n",
            "bert.encoder.layer.16.output.LayerNorm.weight True\n",
            "bert.encoder.layer.16.output.LayerNorm.bias True\n",
            "bert.encoder.layer.17.attention.self.query.weight True\n",
            "bert.encoder.layer.17.attention.self.query.bias True\n",
            "bert.encoder.layer.17.attention.self.key.weight True\n",
            "bert.encoder.layer.17.attention.self.key.bias True\n",
            "bert.encoder.layer.17.attention.self.value.weight True\n",
            "bert.encoder.layer.17.attention.self.value.bias True\n",
            "bert.encoder.layer.17.attention.output.dense.weight True\n",
            "bert.encoder.layer.17.attention.output.dense.bias True\n",
            "bert.encoder.layer.17.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.17.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.17.intermediate.dense.weight True\n",
            "bert.encoder.layer.17.intermediate.dense.bias True\n",
            "bert.encoder.layer.17.output.dense.weight True\n",
            "bert.encoder.layer.17.output.dense.bias True\n",
            "bert.encoder.layer.17.output.LayerNorm.weight True\n",
            "bert.encoder.layer.17.output.LayerNorm.bias True\n",
            "bert.encoder.layer.18.attention.self.query.weight True\n",
            "bert.encoder.layer.18.attention.self.query.bias True\n",
            "bert.encoder.layer.18.attention.self.key.weight True\n",
            "bert.encoder.layer.18.attention.self.key.bias True\n",
            "bert.encoder.layer.18.attention.self.value.weight True\n",
            "bert.encoder.layer.18.attention.self.value.bias True\n",
            "bert.encoder.layer.18.attention.output.dense.weight True\n",
            "bert.encoder.layer.18.attention.output.dense.bias True\n",
            "bert.encoder.layer.18.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.18.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.18.intermediate.dense.weight True\n",
            "bert.encoder.layer.18.intermediate.dense.bias True\n",
            "bert.encoder.layer.18.output.dense.weight True\n",
            "bert.encoder.layer.18.output.dense.bias True\n",
            "bert.encoder.layer.18.output.LayerNorm.weight True\n",
            "bert.encoder.layer.18.output.LayerNorm.bias True\n",
            "bert.encoder.layer.19.attention.self.query.weight True\n",
            "bert.encoder.layer.19.attention.self.query.bias True\n",
            "bert.encoder.layer.19.attention.self.key.weight True\n",
            "bert.encoder.layer.19.attention.self.key.bias True\n",
            "bert.encoder.layer.19.attention.self.value.weight True\n",
            "bert.encoder.layer.19.attention.self.value.bias True\n",
            "bert.encoder.layer.19.attention.output.dense.weight True\n",
            "bert.encoder.layer.19.attention.output.dense.bias True\n",
            "bert.encoder.layer.19.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.19.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.19.intermediate.dense.weight True\n",
            "bert.encoder.layer.19.intermediate.dense.bias True\n",
            "bert.encoder.layer.19.output.dense.weight True\n",
            "bert.encoder.layer.19.output.dense.bias True\n",
            "bert.encoder.layer.19.output.LayerNorm.weight True\n",
            "bert.encoder.layer.19.output.LayerNorm.bias True\n",
            "bert.encoder.layer.20.attention.self.query.weight True\n",
            "bert.encoder.layer.20.attention.self.query.bias True\n",
            "bert.encoder.layer.20.attention.self.key.weight True\n",
            "bert.encoder.layer.20.attention.self.key.bias True\n",
            "bert.encoder.layer.20.attention.self.value.weight True\n",
            "bert.encoder.layer.20.attention.self.value.bias True\n",
            "bert.encoder.layer.20.attention.output.dense.weight True\n",
            "bert.encoder.layer.20.attention.output.dense.bias True\n",
            "bert.encoder.layer.20.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.20.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.20.intermediate.dense.weight True\n",
            "bert.encoder.layer.20.intermediate.dense.bias True\n",
            "bert.encoder.layer.20.output.dense.weight True\n",
            "bert.encoder.layer.20.output.dense.bias True\n",
            "bert.encoder.layer.20.output.LayerNorm.weight True\n",
            "bert.encoder.layer.20.output.LayerNorm.bias True\n",
            "bert.encoder.layer.21.attention.self.query.weight True\n",
            "bert.encoder.layer.21.attention.self.query.bias True\n",
            "bert.encoder.layer.21.attention.self.key.weight True\n",
            "bert.encoder.layer.21.attention.self.key.bias True\n",
            "bert.encoder.layer.21.attention.self.value.weight True\n",
            "bert.encoder.layer.21.attention.self.value.bias True\n",
            "bert.encoder.layer.21.attention.output.dense.weight True\n",
            "bert.encoder.layer.21.attention.output.dense.bias True\n",
            "bert.encoder.layer.21.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.21.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.21.intermediate.dense.weight True\n",
            "bert.encoder.layer.21.intermediate.dense.bias True\n",
            "bert.encoder.layer.21.output.dense.weight True\n",
            "bert.encoder.layer.21.output.dense.bias True\n",
            "bert.encoder.layer.21.output.LayerNorm.weight True\n",
            "bert.encoder.layer.21.output.LayerNorm.bias True\n",
            "bert.encoder.layer.22.attention.self.query.weight True\n",
            "bert.encoder.layer.22.attention.self.query.bias True\n",
            "bert.encoder.layer.22.attention.self.key.weight True\n",
            "bert.encoder.layer.22.attention.self.key.bias True\n",
            "bert.encoder.layer.22.attention.self.value.weight True\n",
            "bert.encoder.layer.22.attention.self.value.bias True\n",
            "bert.encoder.layer.22.attention.output.dense.weight True\n",
            "bert.encoder.layer.22.attention.output.dense.bias True\n",
            "bert.encoder.layer.22.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.22.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.22.intermediate.dense.weight True\n",
            "bert.encoder.layer.22.intermediate.dense.bias True\n",
            "bert.encoder.layer.22.output.dense.weight True\n",
            "bert.encoder.layer.22.output.dense.bias True\n",
            "bert.encoder.layer.22.output.LayerNorm.weight True\n",
            "bert.encoder.layer.22.output.LayerNorm.bias True\n",
            "bert.encoder.layer.23.attention.self.query.weight True\n",
            "bert.encoder.layer.23.attention.self.query.bias True\n",
            "bert.encoder.layer.23.attention.self.key.weight True\n",
            "bert.encoder.layer.23.attention.self.key.bias True\n",
            "bert.encoder.layer.23.attention.self.value.weight True\n",
            "bert.encoder.layer.23.attention.self.value.bias True\n",
            "bert.encoder.layer.23.attention.output.dense.weight True\n",
            "bert.encoder.layer.23.attention.output.dense.bias True\n",
            "bert.encoder.layer.23.attention.output.LayerNorm.weight True\n",
            "bert.encoder.layer.23.attention.output.LayerNorm.bias True\n",
            "bert.encoder.layer.23.intermediate.dense.weight True\n",
            "bert.encoder.layer.23.intermediate.dense.bias True\n",
            "bert.encoder.layer.23.output.dense.weight True\n",
            "bert.encoder.layer.23.output.dense.bias True\n",
            "bert.encoder.layer.23.output.LayerNorm.weight True\n",
            "bert.encoder.layer.23.output.LayerNorm.bias True\n",
            "bert.pooler.dense.weight True\n",
            "bert.pooler.dense.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ],
      "source": [
        "# print layers\n",
        "for name, param in model.named_parameters():\n",
        "   print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "9b569296",
      "metadata": {
        "id": "9b569296"
      },
      "outputs": [],
      "source": [
        "# freeze base model parameters\n",
        "for name, param in model.base_model.named_parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# unfreeze base model pooling layers\n",
        "for name, param in model.base_model.named_parameters():\n",
        "    if \"pooler\" in name:\n",
        "        param.requires_grad = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "161d7c59",
      "metadata": {
        "id": "161d7c59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f1257a-f363-438b-f96d-f60a4c78b186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert.embeddings.word_embeddings.weight False\n",
            "bert.embeddings.position_embeddings.weight False\n",
            "bert.embeddings.token_type_embeddings.weight False\n",
            "bert.embeddings.LayerNorm.weight False\n",
            "bert.embeddings.LayerNorm.bias False\n",
            "bert.encoder.layer.0.attention.self.query.weight False\n",
            "bert.encoder.layer.0.attention.self.query.bias False\n",
            "bert.encoder.layer.0.attention.self.key.weight False\n",
            "bert.encoder.layer.0.attention.self.key.bias False\n",
            "bert.encoder.layer.0.attention.self.value.weight False\n",
            "bert.encoder.layer.0.attention.self.value.bias False\n",
            "bert.encoder.layer.0.attention.output.dense.weight False\n",
            "bert.encoder.layer.0.attention.output.dense.bias False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.0.intermediate.dense.weight False\n",
            "bert.encoder.layer.0.intermediate.dense.bias False\n",
            "bert.encoder.layer.0.output.dense.weight False\n",
            "bert.encoder.layer.0.output.dense.bias False\n",
            "bert.encoder.layer.0.output.LayerNorm.weight False\n",
            "bert.encoder.layer.0.output.LayerNorm.bias False\n",
            "bert.encoder.layer.1.attention.self.query.weight False\n",
            "bert.encoder.layer.1.attention.self.query.bias False\n",
            "bert.encoder.layer.1.attention.self.key.weight False\n",
            "bert.encoder.layer.1.attention.self.key.bias False\n",
            "bert.encoder.layer.1.attention.self.value.weight False\n",
            "bert.encoder.layer.1.attention.self.value.bias False\n",
            "bert.encoder.layer.1.attention.output.dense.weight False\n",
            "bert.encoder.layer.1.attention.output.dense.bias False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.1.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.1.intermediate.dense.weight False\n",
            "bert.encoder.layer.1.intermediate.dense.bias False\n",
            "bert.encoder.layer.1.output.dense.weight False\n",
            "bert.encoder.layer.1.output.dense.bias False\n",
            "bert.encoder.layer.1.output.LayerNorm.weight False\n",
            "bert.encoder.layer.1.output.LayerNorm.bias False\n",
            "bert.encoder.layer.2.attention.self.query.weight False\n",
            "bert.encoder.layer.2.attention.self.query.bias False\n",
            "bert.encoder.layer.2.attention.self.key.weight False\n",
            "bert.encoder.layer.2.attention.self.key.bias False\n",
            "bert.encoder.layer.2.attention.self.value.weight False\n",
            "bert.encoder.layer.2.attention.self.value.bias False\n",
            "bert.encoder.layer.2.attention.output.dense.weight False\n",
            "bert.encoder.layer.2.attention.output.dense.bias False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.2.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.2.intermediate.dense.weight False\n",
            "bert.encoder.layer.2.intermediate.dense.bias False\n",
            "bert.encoder.layer.2.output.dense.weight False\n",
            "bert.encoder.layer.2.output.dense.bias False\n",
            "bert.encoder.layer.2.output.LayerNorm.weight False\n",
            "bert.encoder.layer.2.output.LayerNorm.bias False\n",
            "bert.encoder.layer.3.attention.self.query.weight False\n",
            "bert.encoder.layer.3.attention.self.query.bias False\n",
            "bert.encoder.layer.3.attention.self.key.weight False\n",
            "bert.encoder.layer.3.attention.self.key.bias False\n",
            "bert.encoder.layer.3.attention.self.value.weight False\n",
            "bert.encoder.layer.3.attention.self.value.bias False\n",
            "bert.encoder.layer.3.attention.output.dense.weight False\n",
            "bert.encoder.layer.3.attention.output.dense.bias False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.3.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.3.intermediate.dense.weight False\n",
            "bert.encoder.layer.3.intermediate.dense.bias False\n",
            "bert.encoder.layer.3.output.dense.weight False\n",
            "bert.encoder.layer.3.output.dense.bias False\n",
            "bert.encoder.layer.3.output.LayerNorm.weight False\n",
            "bert.encoder.layer.3.output.LayerNorm.bias False\n",
            "bert.encoder.layer.4.attention.self.query.weight False\n",
            "bert.encoder.layer.4.attention.self.query.bias False\n",
            "bert.encoder.layer.4.attention.self.key.weight False\n",
            "bert.encoder.layer.4.attention.self.key.bias False\n",
            "bert.encoder.layer.4.attention.self.value.weight False\n",
            "bert.encoder.layer.4.attention.self.value.bias False\n",
            "bert.encoder.layer.4.attention.output.dense.weight False\n",
            "bert.encoder.layer.4.attention.output.dense.bias False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.4.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.4.intermediate.dense.weight False\n",
            "bert.encoder.layer.4.intermediate.dense.bias False\n",
            "bert.encoder.layer.4.output.dense.weight False\n",
            "bert.encoder.layer.4.output.dense.bias False\n",
            "bert.encoder.layer.4.output.LayerNorm.weight False\n",
            "bert.encoder.layer.4.output.LayerNorm.bias False\n",
            "bert.encoder.layer.5.attention.self.query.weight False\n",
            "bert.encoder.layer.5.attention.self.query.bias False\n",
            "bert.encoder.layer.5.attention.self.key.weight False\n",
            "bert.encoder.layer.5.attention.self.key.bias False\n",
            "bert.encoder.layer.5.attention.self.value.weight False\n",
            "bert.encoder.layer.5.attention.self.value.bias False\n",
            "bert.encoder.layer.5.attention.output.dense.weight False\n",
            "bert.encoder.layer.5.attention.output.dense.bias False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.5.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.5.intermediate.dense.weight False\n",
            "bert.encoder.layer.5.intermediate.dense.bias False\n",
            "bert.encoder.layer.5.output.dense.weight False\n",
            "bert.encoder.layer.5.output.dense.bias False\n",
            "bert.encoder.layer.5.output.LayerNorm.weight False\n",
            "bert.encoder.layer.5.output.LayerNorm.bias False\n",
            "bert.encoder.layer.6.attention.self.query.weight False\n",
            "bert.encoder.layer.6.attention.self.query.bias False\n",
            "bert.encoder.layer.6.attention.self.key.weight False\n",
            "bert.encoder.layer.6.attention.self.key.bias False\n",
            "bert.encoder.layer.6.attention.self.value.weight False\n",
            "bert.encoder.layer.6.attention.self.value.bias False\n",
            "bert.encoder.layer.6.attention.output.dense.weight False\n",
            "bert.encoder.layer.6.attention.output.dense.bias False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.6.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.6.intermediate.dense.weight False\n",
            "bert.encoder.layer.6.intermediate.dense.bias False\n",
            "bert.encoder.layer.6.output.dense.weight False\n",
            "bert.encoder.layer.6.output.dense.bias False\n",
            "bert.encoder.layer.6.output.LayerNorm.weight False\n",
            "bert.encoder.layer.6.output.LayerNorm.bias False\n",
            "bert.encoder.layer.7.attention.self.query.weight False\n",
            "bert.encoder.layer.7.attention.self.query.bias False\n",
            "bert.encoder.layer.7.attention.self.key.weight False\n",
            "bert.encoder.layer.7.attention.self.key.bias False\n",
            "bert.encoder.layer.7.attention.self.value.weight False\n",
            "bert.encoder.layer.7.attention.self.value.bias False\n",
            "bert.encoder.layer.7.attention.output.dense.weight False\n",
            "bert.encoder.layer.7.attention.output.dense.bias False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.7.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.7.intermediate.dense.weight False\n",
            "bert.encoder.layer.7.intermediate.dense.bias False\n",
            "bert.encoder.layer.7.output.dense.weight False\n",
            "bert.encoder.layer.7.output.dense.bias False\n",
            "bert.encoder.layer.7.output.LayerNorm.weight False\n",
            "bert.encoder.layer.7.output.LayerNorm.bias False\n",
            "bert.encoder.layer.8.attention.self.query.weight False\n",
            "bert.encoder.layer.8.attention.self.query.bias False\n",
            "bert.encoder.layer.8.attention.self.key.weight False\n",
            "bert.encoder.layer.8.attention.self.key.bias False\n",
            "bert.encoder.layer.8.attention.self.value.weight False\n",
            "bert.encoder.layer.8.attention.self.value.bias False\n",
            "bert.encoder.layer.8.attention.output.dense.weight False\n",
            "bert.encoder.layer.8.attention.output.dense.bias False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.8.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.8.intermediate.dense.weight False\n",
            "bert.encoder.layer.8.intermediate.dense.bias False\n",
            "bert.encoder.layer.8.output.dense.weight False\n",
            "bert.encoder.layer.8.output.dense.bias False\n",
            "bert.encoder.layer.8.output.LayerNorm.weight False\n",
            "bert.encoder.layer.8.output.LayerNorm.bias False\n",
            "bert.encoder.layer.9.attention.self.query.weight False\n",
            "bert.encoder.layer.9.attention.self.query.bias False\n",
            "bert.encoder.layer.9.attention.self.key.weight False\n",
            "bert.encoder.layer.9.attention.self.key.bias False\n",
            "bert.encoder.layer.9.attention.self.value.weight False\n",
            "bert.encoder.layer.9.attention.self.value.bias False\n",
            "bert.encoder.layer.9.attention.output.dense.weight False\n",
            "bert.encoder.layer.9.attention.output.dense.bias False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.9.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.9.intermediate.dense.weight False\n",
            "bert.encoder.layer.9.intermediate.dense.bias False\n",
            "bert.encoder.layer.9.output.dense.weight False\n",
            "bert.encoder.layer.9.output.dense.bias False\n",
            "bert.encoder.layer.9.output.LayerNorm.weight False\n",
            "bert.encoder.layer.9.output.LayerNorm.bias False\n",
            "bert.encoder.layer.10.attention.self.query.weight False\n",
            "bert.encoder.layer.10.attention.self.query.bias False\n",
            "bert.encoder.layer.10.attention.self.key.weight False\n",
            "bert.encoder.layer.10.attention.self.key.bias False\n",
            "bert.encoder.layer.10.attention.self.value.weight False\n",
            "bert.encoder.layer.10.attention.self.value.bias False\n",
            "bert.encoder.layer.10.attention.output.dense.weight False\n",
            "bert.encoder.layer.10.attention.output.dense.bias False\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.10.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.10.intermediate.dense.weight False\n",
            "bert.encoder.layer.10.intermediate.dense.bias False\n",
            "bert.encoder.layer.10.output.dense.weight False\n",
            "bert.encoder.layer.10.output.dense.bias False\n",
            "bert.encoder.layer.10.output.LayerNorm.weight False\n",
            "bert.encoder.layer.10.output.LayerNorm.bias False\n",
            "bert.encoder.layer.11.attention.self.query.weight False\n",
            "bert.encoder.layer.11.attention.self.query.bias False\n",
            "bert.encoder.layer.11.attention.self.key.weight False\n",
            "bert.encoder.layer.11.attention.self.key.bias False\n",
            "bert.encoder.layer.11.attention.self.value.weight False\n",
            "bert.encoder.layer.11.attention.self.value.bias False\n",
            "bert.encoder.layer.11.attention.output.dense.weight False\n",
            "bert.encoder.layer.11.attention.output.dense.bias False\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.11.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.11.intermediate.dense.weight False\n",
            "bert.encoder.layer.11.intermediate.dense.bias False\n",
            "bert.encoder.layer.11.output.dense.weight False\n",
            "bert.encoder.layer.11.output.dense.bias False\n",
            "bert.encoder.layer.11.output.LayerNorm.weight False\n",
            "bert.encoder.layer.11.output.LayerNorm.bias False\n",
            "bert.encoder.layer.12.attention.self.query.weight False\n",
            "bert.encoder.layer.12.attention.self.query.bias False\n",
            "bert.encoder.layer.12.attention.self.key.weight False\n",
            "bert.encoder.layer.12.attention.self.key.bias False\n",
            "bert.encoder.layer.12.attention.self.value.weight False\n",
            "bert.encoder.layer.12.attention.self.value.bias False\n",
            "bert.encoder.layer.12.attention.output.dense.weight False\n",
            "bert.encoder.layer.12.attention.output.dense.bias False\n",
            "bert.encoder.layer.12.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.12.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.12.intermediate.dense.weight False\n",
            "bert.encoder.layer.12.intermediate.dense.bias False\n",
            "bert.encoder.layer.12.output.dense.weight False\n",
            "bert.encoder.layer.12.output.dense.bias False\n",
            "bert.encoder.layer.12.output.LayerNorm.weight False\n",
            "bert.encoder.layer.12.output.LayerNorm.bias False\n",
            "bert.encoder.layer.13.attention.self.query.weight False\n",
            "bert.encoder.layer.13.attention.self.query.bias False\n",
            "bert.encoder.layer.13.attention.self.key.weight False\n",
            "bert.encoder.layer.13.attention.self.key.bias False\n",
            "bert.encoder.layer.13.attention.self.value.weight False\n",
            "bert.encoder.layer.13.attention.self.value.bias False\n",
            "bert.encoder.layer.13.attention.output.dense.weight False\n",
            "bert.encoder.layer.13.attention.output.dense.bias False\n",
            "bert.encoder.layer.13.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.13.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.13.intermediate.dense.weight False\n",
            "bert.encoder.layer.13.intermediate.dense.bias False\n",
            "bert.encoder.layer.13.output.dense.weight False\n",
            "bert.encoder.layer.13.output.dense.bias False\n",
            "bert.encoder.layer.13.output.LayerNorm.weight False\n",
            "bert.encoder.layer.13.output.LayerNorm.bias False\n",
            "bert.encoder.layer.14.attention.self.query.weight False\n",
            "bert.encoder.layer.14.attention.self.query.bias False\n",
            "bert.encoder.layer.14.attention.self.key.weight False\n",
            "bert.encoder.layer.14.attention.self.key.bias False\n",
            "bert.encoder.layer.14.attention.self.value.weight False\n",
            "bert.encoder.layer.14.attention.self.value.bias False\n",
            "bert.encoder.layer.14.attention.output.dense.weight False\n",
            "bert.encoder.layer.14.attention.output.dense.bias False\n",
            "bert.encoder.layer.14.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.14.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.14.intermediate.dense.weight False\n",
            "bert.encoder.layer.14.intermediate.dense.bias False\n",
            "bert.encoder.layer.14.output.dense.weight False\n",
            "bert.encoder.layer.14.output.dense.bias False\n",
            "bert.encoder.layer.14.output.LayerNorm.weight False\n",
            "bert.encoder.layer.14.output.LayerNorm.bias False\n",
            "bert.encoder.layer.15.attention.self.query.weight False\n",
            "bert.encoder.layer.15.attention.self.query.bias False\n",
            "bert.encoder.layer.15.attention.self.key.weight False\n",
            "bert.encoder.layer.15.attention.self.key.bias False\n",
            "bert.encoder.layer.15.attention.self.value.weight False\n",
            "bert.encoder.layer.15.attention.self.value.bias False\n",
            "bert.encoder.layer.15.attention.output.dense.weight False\n",
            "bert.encoder.layer.15.attention.output.dense.bias False\n",
            "bert.encoder.layer.15.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.15.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.15.intermediate.dense.weight False\n",
            "bert.encoder.layer.15.intermediate.dense.bias False\n",
            "bert.encoder.layer.15.output.dense.weight False\n",
            "bert.encoder.layer.15.output.dense.bias False\n",
            "bert.encoder.layer.15.output.LayerNorm.weight False\n",
            "bert.encoder.layer.15.output.LayerNorm.bias False\n",
            "bert.encoder.layer.16.attention.self.query.weight False\n",
            "bert.encoder.layer.16.attention.self.query.bias False\n",
            "bert.encoder.layer.16.attention.self.key.weight False\n",
            "bert.encoder.layer.16.attention.self.key.bias False\n",
            "bert.encoder.layer.16.attention.self.value.weight False\n",
            "bert.encoder.layer.16.attention.self.value.bias False\n",
            "bert.encoder.layer.16.attention.output.dense.weight False\n",
            "bert.encoder.layer.16.attention.output.dense.bias False\n",
            "bert.encoder.layer.16.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.16.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.16.intermediate.dense.weight False\n",
            "bert.encoder.layer.16.intermediate.dense.bias False\n",
            "bert.encoder.layer.16.output.dense.weight False\n",
            "bert.encoder.layer.16.output.dense.bias False\n",
            "bert.encoder.layer.16.output.LayerNorm.weight False\n",
            "bert.encoder.layer.16.output.LayerNorm.bias False\n",
            "bert.encoder.layer.17.attention.self.query.weight False\n",
            "bert.encoder.layer.17.attention.self.query.bias False\n",
            "bert.encoder.layer.17.attention.self.key.weight False\n",
            "bert.encoder.layer.17.attention.self.key.bias False\n",
            "bert.encoder.layer.17.attention.self.value.weight False\n",
            "bert.encoder.layer.17.attention.self.value.bias False\n",
            "bert.encoder.layer.17.attention.output.dense.weight False\n",
            "bert.encoder.layer.17.attention.output.dense.bias False\n",
            "bert.encoder.layer.17.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.17.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.17.intermediate.dense.weight False\n",
            "bert.encoder.layer.17.intermediate.dense.bias False\n",
            "bert.encoder.layer.17.output.dense.weight False\n",
            "bert.encoder.layer.17.output.dense.bias False\n",
            "bert.encoder.layer.17.output.LayerNorm.weight False\n",
            "bert.encoder.layer.17.output.LayerNorm.bias False\n",
            "bert.encoder.layer.18.attention.self.query.weight False\n",
            "bert.encoder.layer.18.attention.self.query.bias False\n",
            "bert.encoder.layer.18.attention.self.key.weight False\n",
            "bert.encoder.layer.18.attention.self.key.bias False\n",
            "bert.encoder.layer.18.attention.self.value.weight False\n",
            "bert.encoder.layer.18.attention.self.value.bias False\n",
            "bert.encoder.layer.18.attention.output.dense.weight False\n",
            "bert.encoder.layer.18.attention.output.dense.bias False\n",
            "bert.encoder.layer.18.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.18.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.18.intermediate.dense.weight False\n",
            "bert.encoder.layer.18.intermediate.dense.bias False\n",
            "bert.encoder.layer.18.output.dense.weight False\n",
            "bert.encoder.layer.18.output.dense.bias False\n",
            "bert.encoder.layer.18.output.LayerNorm.weight False\n",
            "bert.encoder.layer.18.output.LayerNorm.bias False\n",
            "bert.encoder.layer.19.attention.self.query.weight False\n",
            "bert.encoder.layer.19.attention.self.query.bias False\n",
            "bert.encoder.layer.19.attention.self.key.weight False\n",
            "bert.encoder.layer.19.attention.self.key.bias False\n",
            "bert.encoder.layer.19.attention.self.value.weight False\n",
            "bert.encoder.layer.19.attention.self.value.bias False\n",
            "bert.encoder.layer.19.attention.output.dense.weight False\n",
            "bert.encoder.layer.19.attention.output.dense.bias False\n",
            "bert.encoder.layer.19.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.19.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.19.intermediate.dense.weight False\n",
            "bert.encoder.layer.19.intermediate.dense.bias False\n",
            "bert.encoder.layer.19.output.dense.weight False\n",
            "bert.encoder.layer.19.output.dense.bias False\n",
            "bert.encoder.layer.19.output.LayerNorm.weight False\n",
            "bert.encoder.layer.19.output.LayerNorm.bias False\n",
            "bert.encoder.layer.20.attention.self.query.weight False\n",
            "bert.encoder.layer.20.attention.self.query.bias False\n",
            "bert.encoder.layer.20.attention.self.key.weight False\n",
            "bert.encoder.layer.20.attention.self.key.bias False\n",
            "bert.encoder.layer.20.attention.self.value.weight False\n",
            "bert.encoder.layer.20.attention.self.value.bias False\n",
            "bert.encoder.layer.20.attention.output.dense.weight False\n",
            "bert.encoder.layer.20.attention.output.dense.bias False\n",
            "bert.encoder.layer.20.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.20.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.20.intermediate.dense.weight False\n",
            "bert.encoder.layer.20.intermediate.dense.bias False\n",
            "bert.encoder.layer.20.output.dense.weight False\n",
            "bert.encoder.layer.20.output.dense.bias False\n",
            "bert.encoder.layer.20.output.LayerNorm.weight False\n",
            "bert.encoder.layer.20.output.LayerNorm.bias False\n",
            "bert.encoder.layer.21.attention.self.query.weight False\n",
            "bert.encoder.layer.21.attention.self.query.bias False\n",
            "bert.encoder.layer.21.attention.self.key.weight False\n",
            "bert.encoder.layer.21.attention.self.key.bias False\n",
            "bert.encoder.layer.21.attention.self.value.weight False\n",
            "bert.encoder.layer.21.attention.self.value.bias False\n",
            "bert.encoder.layer.21.attention.output.dense.weight False\n",
            "bert.encoder.layer.21.attention.output.dense.bias False\n",
            "bert.encoder.layer.21.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.21.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.21.intermediate.dense.weight False\n",
            "bert.encoder.layer.21.intermediate.dense.bias False\n",
            "bert.encoder.layer.21.output.dense.weight False\n",
            "bert.encoder.layer.21.output.dense.bias False\n",
            "bert.encoder.layer.21.output.LayerNorm.weight False\n",
            "bert.encoder.layer.21.output.LayerNorm.bias False\n",
            "bert.encoder.layer.22.attention.self.query.weight False\n",
            "bert.encoder.layer.22.attention.self.query.bias False\n",
            "bert.encoder.layer.22.attention.self.key.weight False\n",
            "bert.encoder.layer.22.attention.self.key.bias False\n",
            "bert.encoder.layer.22.attention.self.value.weight False\n",
            "bert.encoder.layer.22.attention.self.value.bias False\n",
            "bert.encoder.layer.22.attention.output.dense.weight False\n",
            "bert.encoder.layer.22.attention.output.dense.bias False\n",
            "bert.encoder.layer.22.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.22.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.22.intermediate.dense.weight False\n",
            "bert.encoder.layer.22.intermediate.dense.bias False\n",
            "bert.encoder.layer.22.output.dense.weight False\n",
            "bert.encoder.layer.22.output.dense.bias False\n",
            "bert.encoder.layer.22.output.LayerNorm.weight False\n",
            "bert.encoder.layer.22.output.LayerNorm.bias False\n",
            "bert.encoder.layer.23.attention.self.query.weight False\n",
            "bert.encoder.layer.23.attention.self.query.bias False\n",
            "bert.encoder.layer.23.attention.self.key.weight False\n",
            "bert.encoder.layer.23.attention.self.key.bias False\n",
            "bert.encoder.layer.23.attention.self.value.weight False\n",
            "bert.encoder.layer.23.attention.self.value.bias False\n",
            "bert.encoder.layer.23.attention.output.dense.weight False\n",
            "bert.encoder.layer.23.attention.output.dense.bias False\n",
            "bert.encoder.layer.23.attention.output.LayerNorm.weight False\n",
            "bert.encoder.layer.23.attention.output.LayerNorm.bias False\n",
            "bert.encoder.layer.23.intermediate.dense.weight False\n",
            "bert.encoder.layer.23.intermediate.dense.bias False\n",
            "bert.encoder.layer.23.output.dense.weight False\n",
            "bert.encoder.layer.23.output.dense.bias False\n",
            "bert.encoder.layer.23.output.LayerNorm.weight False\n",
            "bert.encoder.layer.23.output.LayerNorm.bias False\n",
            "bert.pooler.dense.weight True\n",
            "bert.pooler.dense.bias True\n",
            "classifier.weight True\n",
            "classifier.bias True\n"
          ]
        }
      ],
      "source": [
        "# print layers\n",
        "for name, param in model.named_parameters():\n",
        "   print(name, param.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d2e421a",
      "metadata": {
        "id": "5d2e421a"
      },
      "source": [
        "#### Preprocess text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "cf0dc1e1",
      "metadata": {
        "id": "cf0dc1e1"
      },
      "outputs": [],
      "source": [
        "# define text preprocessing\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "b42616c7",
      "metadata": {
        "id": "b42616c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "3f157498af1c4d2a9f2ec9b73a5833c9",
            "a9a90c1d576f4a08aa03aebef3bd4ca2",
            "0e7ad7fc8cc84074b9f0fb434da0542f",
            "6b76af36319c4789934c0566f78f9d18",
            "b18bdeee6e7d4e198106ab7b384d01f4",
            "1d6abf3273c24255a0839edca693ff82",
            "c34fee800f6b4bc397bf78ba88e2d3e4",
            "583582f7401542799947848332da90b5",
            "72dc6527c28b435f92899657709acdc1",
            "0a43f64944af491f91ab8960fe75210e",
            "75d0e8d28e8d4016841bce119c8246ee"
          ]
        },
        "outputId": "9e6edc6f-3f65-417e-dffa-517242c748c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/534 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f157498af1c4d2a9f2ec9b73a5833c9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# tokenize all datasetse\n",
        "tokenized_data = dataset_dict.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "04a04a18",
      "metadata": {
        "id": "04a04a18"
      },
      "outputs": [],
      "source": [
        "# create data collator\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e2ce8c7",
      "metadata": {
        "id": "7e2ce8c7"
      },
      "source": [
        "#### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "16b12c6d",
      "metadata": {
        "id": "16b12c6d"
      },
      "outputs": [],
      "source": [
        "# load metrics\n",
        "accuracy = evaluate.load(\"accuracy\")\n",
        "auc_score = evaluate.load(\"roc_auc\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    # get predictions\n",
        "    predictions, labels = eval_pred\n",
        "\n",
        "    # apply softmax to get probabilities\n",
        "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, keepdims=True)\n",
        "    # use probabilities of the positive class for ROC AUC\n",
        "    positive_class_probs = probabilities[:, 1]\n",
        "    # compute auc\n",
        "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, references=labels)['roc_auc'],3)\n",
        "\n",
        "    # predict most probable class\n",
        "    predicted_classes = np.argmax(predictions, axis=1)\n",
        "    # compute accuracy\n",
        "    acc = np.round(accuracy.compute(predictions=predicted_classes, references=labels)['accuracy'],3)\n",
        "\n",
        "    return {\"Accuracy\": acc, \"AUC\": auc}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68613386",
      "metadata": {
        "id": "68613386"
      },
      "source": [
        "#### Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "579f1230",
      "metadata": {
        "id": "579f1230"
      },
      "outputs": [],
      "source": [
        "# hyperparameters\n",
        "lr = 2e-4\n",
        "batch_size = 8\n",
        "num_epochs = 10\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"bert-slang-detector\",\n",
        "    learning_rate=lr,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    num_train_epochs=num_epochs,\n",
        "    logging_strategy=\"epoch\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "7c4df3d5",
      "metadata": {
        "id": "7c4df3d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "outputId": "c97c9dbc-2fb9-4697-c258-b54865f3cce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-51-25805d4bc91c>:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3120' max='3120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3120/3120 09:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Auc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.128500</td>\n",
              "      <td>0.046029</td>\n",
              "      <td>0.981000</td>\n",
              "      <td>0.999000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.053700</td>\n",
              "      <td>0.033784</td>\n",
              "      <td>0.985000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.038600</td>\n",
              "      <td>0.024812</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.028700</td>\n",
              "      <td>0.021564</td>\n",
              "      <td>0.991000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.030174</td>\n",
              "      <td>0.991000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.020639</td>\n",
              "      <td>0.991000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.016700</td>\n",
              "      <td>0.024137</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.018300</td>\n",
              "      <td>0.026354</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.021000</td>\n",
              "      <td>0.024136</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.018100</td>\n",
              "      <td>0.024296</td>\n",
              "      <td>0.989000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3120, training_loss=0.03743554307864262, metrics={'train_runtime': 592.1156, 'train_samples_per_second': 42.053, 'train_steps_per_second': 5.269, 'total_flos': 2059062303347448.0, 'train_loss': 0.03743554307864262, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    eval_dataset=tokenized_data[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf6b12cc",
      "metadata": {
        "id": "cf6b12cc"
      },
      "source": [
        "### Apply Model to Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "ba1f2710",
      "metadata": {
        "id": "ba1f2710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d3a3a0b-78b2-4970-9259-9ae8407cbc88"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Accuracy': 0.994, 'AUC': 0.999}\n"
          ]
        }
      ],
      "source": [
        "# apply model to validation dataset\n",
        "predictions = trainer.predict(tokenized_data[\"dev\"])\n",
        "\n",
        "# Extract the logits and labels from the predictions object\n",
        "logits = predictions.predictions\n",
        "labels = predictions.label_ids\n",
        "\n",
        "# Use your compute_metrics function\n",
        "metrics = compute_metrics((logits, labels))\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "predictions = trainer.predict(tokenized_data[\"test\"])\n",
        "\n",
        "# Extract logits, true labels, and metrics\n",
        "logits = predictions.predictions\n",
        "labels = predictions.label_ids\n",
        "predicted_labels = np.argmax(logits, axis=-1)\n",
        "\n",
        "# Print evaluation metrics\n",
        "print(\"Test Metrics:\", predictions.metrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "DnvpN6-RUYhz",
        "outputId": "38932101-ea8c-4950-fd09-38e771758b5d"
      },
      "id": "DnvpN6-RUYhz",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Metrics: {'test_loss': 0.020639292895793915, 'test_Accuracy': 0.991, 'test_AUC': 1.0, 'test_runtime': 5.1863, 'test_samples_per_second': 102.963, 'test_steps_per_second': 12.919}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame({\n",
        "    \"text\": tokenized_data[\"test\"][\"text\"],  # Original text from test set\n",
        "    \"true_label\": labels,\n",
        "    \"predicted_label\": predicted_labels\n",
        "})\n",
        "\n",
        "# Display the first few rows\n",
        "print(results_df.head())\n",
        "\n",
        "# Save results to a CSV file for detailed inspection\n",
        "results_df.to_csv(\"test_results.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROtKd-kaUjYW",
        "outputId": "98865a5c-f89a-468b-f18d-4d439c6609e3"
      },
      "id": "ROtKd-kaUjYW",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  true_label  \\\n",
            "0            She's absolutely stunning, a real BUBU.           1   \n",
            "1  Vista Chemical Co., with three chemical plants...           0   \n",
            "2  The base rate on corporate loans at large U.S....           0   \n",
            "3           Things got heated last night, total UDS.           1   \n",
            "4  Either way it was a pity, because Mr. Stolzman...           0   \n",
            "\n",
            "   predicted_label  \n",
            "0                1  \n",
            "1                0  \n",
            "2                0  \n",
            "3                1  \n",
            "4                0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "766329b3",
      "metadata": {
        "id": "766329b3"
      },
      "source": [
        "### Push to hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "eb89b178",
      "metadata": {
        "id": "eb89b178"
      },
      "outputs": [],
      "source": [
        "# push model to hub\n",
        "# trainer.push_to_hub()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3f157498af1c4d2a9f2ec9b73a5833c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a9a90c1d576f4a08aa03aebef3bd4ca2",
              "IPY_MODEL_0e7ad7fc8cc84074b9f0fb434da0542f",
              "IPY_MODEL_6b76af36319c4789934c0566f78f9d18"
            ],
            "layout": "IPY_MODEL_b18bdeee6e7d4e198106ab7b384d01f4"
          }
        },
        "a9a90c1d576f4a08aa03aebef3bd4ca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d6abf3273c24255a0839edca693ff82",
            "placeholder": "",
            "style": "IPY_MODEL_c34fee800f6b4bc397bf78ba88e2d3e4",
            "value": "Map:100%"
          }
        },
        "0e7ad7fc8cc84074b9f0fb434da0542f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_583582f7401542799947848332da90b5",
            "max": 534,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72dc6527c28b435f92899657709acdc1",
            "value": 534
          }
        },
        "6b76af36319c4789934c0566f78f9d18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a43f64944af491f91ab8960fe75210e",
            "placeholder": "",
            "style": "IPY_MODEL_75d0e8d28e8d4016841bce119c8246ee",
            "value": "534/534[00:00&lt;00:00,2647.91examples/s]"
          }
        },
        "b18bdeee6e7d4e198106ab7b384d01f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d6abf3273c24255a0839edca693ff82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c34fee800f6b4bc397bf78ba88e2d3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "583582f7401542799947848332da90b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72dc6527c28b435f92899657709acdc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0a43f64944af491f91ab8960fe75210e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75d0e8d28e8d4016841bce119c8246ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}