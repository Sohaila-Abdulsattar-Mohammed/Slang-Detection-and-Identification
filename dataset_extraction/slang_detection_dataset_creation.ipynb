{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "open sub positive labels dataset filtered with annotator text 2,3\n",
        "\n",
        "2256 rows"
      ],
      "metadata": {
        "id": "kD_S2fM2HU7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nILOG22_kPuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbac4404-6065-4893-aaf6-7e834ca05da0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  labels\n",
            "0     My wife's had an accident with some Quaaludes.       1\n",
            "1  You just can't put me on watch dog anymore, al...       1\n",
            "2  I'm sorry, but, you know, you can't barge in a...       1\n",
            "3  We got movement definitely on Tuesday of that ...       1\n",
            "4  I waited until you broke up with her, but me too.       1\n",
            "The number of rows in the new dataset is: 2256\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_dataset(dataframe):\n",
        "    \"\"\"\n",
        "    Filters the dataset for rows with ANNOTATOR_CONFIDENCE values 2 and 3,\n",
        "    and creates a new dataset with 'text' and 'labels' columns.\n",
        "    \"\"\"\n",
        "    # Filter rows where 'ANNOTATOR_CONFIDENCE' is 2 or 3\n",
        "    filtered_data = dataframe[dataframe['ANNOTATOR_CONFIDENCE'].isin([2, 3])]\n",
        "\n",
        "    # Create a new dataset with required columns\n",
        "    new_dataset = pd.DataFrame({\n",
        "        'text': filtered_data['SENTENCE'],\n",
        "        'labels': 1  # Assigning 1 to all rows in the 'labels' column\n",
        "    })\n",
        "\n",
        "    return new_dataset\n",
        "\n",
        "# Example usage:\n",
        "df = pd.read_csv('slang_OpenSub_positive.tsv', sep='\\t')  # Replace 'your_file.tsv' with the actual filename\n",
        "open_sub_postive_df = process_dataset(df)\n",
        "open_sub_postive_df.reset_index(drop=True, inplace=True)\n",
        "print(open_sub_postive_df.head())\n",
        "\n",
        "row_count = open_sub_postive_df.shape[0]\n",
        "print(f\"The number of rows in the new dataset is: {row_count}\")\n",
        "\n",
        "#new_df.to_csv('filtered_slang_dataset.csv', index=False)  # Save the new dataset to a file\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "open sub negative/ non slang sentences\n",
        "\n",
        "17512 rows"
      ],
      "metadata": {
        "id": "AOZHkdVSHgP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Function to process the dataset\n",
        "def create_non_slang_dataset(dataframe):\n",
        "    \"\"\"\n",
        "    Creates a new dataset where sentences are stored in a column named 'text'\n",
        "    and labels are assigned the value 0 (non-slang sentences).\n",
        "    \"\"\"\n",
        "    # Create the new dataset with 'text' and 'labels' columns\n",
        "    new_dataset = pd.DataFrame({\n",
        "        'text': dataframe['SENTENCE'],\n",
        "        'labels': 0  # Assigning 0 to all rows in the 'labels' column\n",
        "    })\n",
        "\n",
        "    return new_dataset\n",
        "\n",
        "# Example usage:\n",
        "df = pd.read_csv('slang_OpenSub_negatives.tsv', sep='\\t')\n",
        "open_sub_negative_df = create_non_slang_dataset(df)\n",
        "print(open_sub_negative_df.head())\n",
        "\n",
        "row_count = open_sub_negative_df.shape[0]\n",
        "print(f\"The number of rows in the new dataset is: {row_count}\")\n",
        "# non_slang_dataset.to_csv('non_slang_dataset.csv', index=False)  # Save the dataset to a file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79-c4aYfJwa4",
        "outputId": "9fa1251a-eb24-4ba1-e31b-59e0d58301f1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  labels\n",
            "0                Oh, man, you made friends with' em.       0\n",
            "1  He could pitch a hundred-mile-an-hour fastball...       0\n",
            "2                       It's an account, that's all.       0\n",
            "3          I thought you were the assistant manager.       0\n",
            "4            On September 12th, 2001, that was over.       0\n",
            "The number of rows in the new dataset is: 17512\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "genz dataset with positive labels\n",
        "\n",
        "1779 rows"
      ],
      "metadata": {
        "id": "MXWd4lfbHoxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_textfile_to_dataframe(file_path):\n",
        "    \"\"\"\n",
        "    Reads a text file and processes it into a DataFrame.\n",
        "    Each line is split into two columns:\n",
        "    - 'text': The first sentence before the first tab.\n",
        "    - 'label': The number after the first tab.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the input text file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with 'text' and 'label' columns.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    # Read the text file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            # Split the line at the first tab\n",
        "            parts = line.strip().split('\\t', 1)  # Split into at most 2 parts\n",
        "            if len(parts) == 2:\n",
        "                text = parts[0]  # First part before the tab\n",
        "                label = parts[1]  # Second part after the tab\n",
        "                data.append((text, label))  # Append as a tuple\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data, columns=['text', 'labels'])\n",
        "    return df\n",
        "\n",
        "# Example Usage\n",
        "file_path = \"genz_slang_sentences_with_tags.txt\"  # Replace with your file path\n",
        "genz_positive_df = process_textfile_to_dataframe(file_path)\n",
        "print(genz_positive_df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBZ036QcHn4m",
        "outputId": "26024479-efda-4ca0-f60c-fe7f8dafe4eb"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text labels\n",
            "0                          Got the job today, big W!      1\n",
            "1           I forgot my wallet at home, thatâ€™s an L.      1\n",
            "2  Your tweet got 5 likes and 100 replies calling...      1\n",
            "3                              That meme is so dank!      1\n",
            "4  That phrase is so cheugy, no one says that any...      1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "wsj dataset filtered for long sentences: 27055 rows"
      ],
      "metadata": {
        "id": "2WLifvMaLnl7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def process_textfile_to_dataframe(file_path):\n",
        "    \"\"\"\n",
        "    Reads a text file and processes it into a DataFrame.\n",
        "    Each line is split into two columns:\n",
        "    - 'text': The first sentence before the first tab.\n",
        "    - 'label': The number after the first tab.\n",
        "    Sentences longer than 180 characters are excluded.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the input text file.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A DataFrame with 'text' and 'label' columns.\n",
        "    \"\"\"\n",
        "    data = []\n",
        "\n",
        "    # Read the text file\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        for line in file:\n",
        "            # Split the line at the first tab\n",
        "            parts = line.strip().split('\\t', 1)  # Split into at most 2 parts\n",
        "            if len(parts) == 2:\n",
        "                text = parts[0]  # First part before the tab\n",
        "                label = parts[1]  # Second part after the tab\n",
        "                # Exclude sentences longer than 180 characters\n",
        "                if len(text) <= 100:\n",
        "                    data.append((text, label))  # Append as a tuple\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data, columns=['text', 'labels'])\n",
        "    return df\n",
        "\n",
        "\n",
        "\n",
        "file_path = \"wsj_sentences_with_tags.txt\"  # Replace with your file path\n",
        "wsj_negative_df = process_textfile_to_dataframe(file_path)\n",
        "print(wsj_negative_df.head())\n",
        "print(wsj_negative_df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9wGkoqXI57Z",
        "outputId": "ac5bd5f7-88a7-4602-df80-a7ed157cb8b4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text labels\n",
            "0  Pierre Vinken, 61 years old, will join the boa...      0\n",
            "1  Mr. Vinken is chairman of Elsevier N.V., the D...      0\n",
            "2  A Lorillard spokewoman said, \"This is an old s...      0\n",
            "3  We're talking about years ago before anyone he...      0\n",
            "4  From 1953 to 1955, 9.8 billion Kent cigarettes...      0\n",
            "(11893, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure 'labels' column is consistent (convert to integer type)\n",
        "for df in [open_sub_postive_df, genz_positive_df, open_sub_negative_df, wsj_negative_df]:\n",
        "    df['labels'] = df['labels'].astype(int)\n",
        "\n",
        "# Concatenate positive samples into one DataFrame\n",
        "positive_df = pd.concat([open_sub_postive_df, genz_positive_df], ignore_index=True)\n",
        "\n",
        "# Sample negative labels from each negative dataset\n",
        "opensub_negative_sample = open_sub_negative_df.sample(n=2017, random_state=42)\n",
        "wsj_negative_sample = wsj_negative_df.sample(n=2018, random_state=42)\n",
        "\n",
        "# Concatenate negative samples into one DataFrame\n",
        "negative_df = pd.concat([opensub_negative_sample, wsj_negative_sample], ignore_index=True)\n",
        "\n",
        "# Combine positive and negative samples into the final DataFrame\n",
        "final_df = pd.concat([positive_df, negative_df], ignore_index=True)\n",
        "\n",
        "# Shuffle the final DataFrame\n",
        "final_df = final_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Save the final DataFrame to a file\n",
        "final_df.to_csv('final_dataset.csv', index=False)\n",
        "\n",
        "print(f\"Final dataset saved with {final_df.shape[0]} rows and the following label distribution:\")\n",
        "print(final_df['labels'].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ui3puF5vNecX",
        "outputId": "36514313-fffd-483e-8563-c6563db4e3eb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final dataset saved with 8070 rows and the following label distribution:\n",
            "labels\n",
            "1    4035\n",
            "0    4035\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}